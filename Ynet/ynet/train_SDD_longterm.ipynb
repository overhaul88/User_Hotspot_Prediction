{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "determined-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import argparse\n",
    "import torch\n",
    "from model import YNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "finished-potential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fc1d7",
   "metadata": {},
   "source": [
    "#### Some hyperparameters and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "arabic-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = 'config/sdd_longterm.yaml'  # yaml config file containing all the hyperparameters\n",
    "EXPERIMENT_NAME = 'sdd_longterm'  # arbitrary name for this experiment\n",
    "DATASET_NAME = 'sdd'\n",
    "\n",
    "TRAIN_DATA_PATH = 'data/SDD/train_longterm.pkl'\n",
    "TRAIN_IMAGE_PATH = 'data/SDD/train'\n",
    "VAL_DATA_PATH = 'data/SDD/test_longterm.pkl'\n",
    "VAL_IMAGE_PATH = 'data/SDD/test'\n",
    "OBS_LEN = 5  # in timesteps\n",
    "PRED_LEN = 30  # in timesteps\n",
    "NUM_GOALS = 20  # K_e\n",
    "NUM_TRAJ = 1  # K_a\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74062c",
   "metadata": {},
   "source": [
    "#### Load config file and print hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dangerous-cutting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resize': 0.25,\n",
       " 'batch_size': 8,\n",
       " 'viz_epoch': 10,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_epochs': 300,\n",
       " 'encoder_channels': [32, 32, 64, 64, 64],\n",
       " 'decoder_channels': [64, 64, 64, 32, 32],\n",
       " 'waypoints': [14, 29],\n",
       " 'temperature': 1.8,\n",
       " 'segmentation_model_fp': 'segmentation_models/SDD_segmentation.pth',\n",
       " 'semantic_classes': 6,\n",
       " 'loss_scale': 1000,\n",
       " 'kernlen': 31,\n",
       " 'nsig': 4,\n",
       " 'use_features_only': False,\n",
       " 'unfreeze': 100,\n",
       " 'use_TTST': True,\n",
       " 'rel_threshold': 0.002,\n",
       " 'use_CWS': True,\n",
       " 'CWS_params': {'sigma_factor': 6, 'ratio': 2, 'rot': True}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(CONFIG_FILE_PATH) as file:\n",
    "    params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "experiment_name = CONFIG_FILE_PATH.split('.yaml')[0].split('config/')[1]\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-pressure",
   "metadata": {},
   "source": [
    "#### Load preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "german-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(TRAIN_DATA_PATH)\n",
    "df_val = pd.read_pickle(VAL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "corporate-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackId</th>\n",
       "      <th>frame</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>sceneId</th>\n",
       "      <th>metaId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6881</td>\n",
       "      <td>17.0</td>\n",
       "      <td>893.5</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6911</td>\n",
       "      <td>31.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6941</td>\n",
       "      <td>63.0</td>\n",
       "      <td>910.5</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6971</td>\n",
       "      <td>98.5</td>\n",
       "      <td>917.5</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7001</td>\n",
       "      <td>134.0</td>\n",
       "      <td>919.5</td>\n",
       "      <td>bookstore_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trackId  frame      x      y      sceneId  metaId\n",
       "0        2   6881   17.0  893.5  bookstore_0       0\n",
       "1        2   6911   31.0  904.0  bookstore_0       0\n",
       "2        2   6941   63.0  910.5  bookstore_0       0\n",
       "3        2   6971   98.5  917.5  bookstore_0       0\n",
       "4        2   7001  134.0  919.5  bookstore_0       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ade5e2",
   "metadata": {},
   "source": [
    "#### Initiate model and load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "harmful-colleague",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segmentation_models_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\AKG\\GSN\\Human-Path-Prediction\\ynet\\train_SDD_longterm.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AKG/GSN/Human-Path-Prediction/ynet/train_SDD_longterm.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m YNet(obs_len\u001b[39m=\u001b[39;49mOBS_LEN, pred_len\u001b[39m=\u001b[39;49mPRED_LEN, params\u001b[39m=\u001b[39;49mparams)\n",
      "File \u001b[1;32md:\\AKG\\GSN\\Human-Path-Prediction\\ynet\\model.py:210\u001b[0m, in \u001b[0;36mYNet.__init__\u001b[1;34m(self, obs_len, pred_len, params)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_len \u001b[39m=\u001b[39m pred_len\n\u001b[0;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdivision_factor \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(params[\u001b[39m'\u001b[39m\u001b[39mencoder_channels\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 210\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m YNetTorch(obs_len\u001b[39m=\u001b[39;49mobs_len,\n\u001b[0;32m    211\u001b[0m \t\t\t\t\t   pred_len\u001b[39m=\u001b[39;49mpred_len,\n\u001b[0;32m    212\u001b[0m \t\t\t\t\t   segmentation_model_fp\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39msegmentation_model_fp\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    213\u001b[0m \t\t\t\t\t   use_features_only\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39muse_features_only\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    214\u001b[0m \t\t\t\t\t   semantic_classes\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39msemantic_classes\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    215\u001b[0m \t\t\t\t\t   encoder_channels\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mencoder_channels\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    216\u001b[0m \t\t\t\t\t   decoder_channels\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mdecoder_channels\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    217\u001b[0m \t\t\t\t\t   waypoints\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(params[\u001b[39m'\u001b[39;49m\u001b[39mwaypoints\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n",
      "File \u001b[1;32md:\\AKG\\GSN\\Human-Path-Prediction\\ynet\\model.py:139\u001b[0m, in \u001b[0;36mYNetTorch.__init__\u001b[1;34m(self, obs_len, pred_len, segmentation_model_fp, use_features_only, semantic_classes, encoder_channels, decoder_channels, waypoints)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39msuper\u001b[39m(YNetTorch, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m    138\u001b[0m \u001b[39mif\u001b[39;00m segmentation_model_fp \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msemantic_segmentation \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mAKG\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mGSN\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mHuman-Path-Prediction\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mynet\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39msegmentation_models\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mSDD_segmentation.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m \t\u001b[39mif\u001b[39;00m use_features_only:\n\u001b[0;32m    141\u001b[0m \t\t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msemantic_segmentation\u001b[39m.\u001b[39msegmentation_head \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mIdentity()\n",
      "File \u001b[1;32mc:\\Users\\adeel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:795\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    794\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32mc:\\Users\\adeel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:1012\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1010\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1011\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[1;32m-> 1012\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1014\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1016\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adeel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:828\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 828\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfind_class(mod_name, name)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'segmentation_models_pytorch'"
     ]
    }
   ],
   "source": [
    "model = YNet(obs_len=OBS_LEN, pred_len=PRED_LEN, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a2a2c",
   "metadata": {},
   "source": [
    "#### Start training\n",
    "Note, the Val ADE and FDE are without TTST and CWS to save time. Therefore, the numbers will be worse than the final values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(df_train, df_val, params, train_image_path=TRAIN_IMAGE_PATH, val_image_path=VAL_IMAGE_PATH,\n",
    "            experiment_name=EXPERIMENT_NAME, batch_size=BATCH_SIZE, num_goals=NUM_GOALS, num_traj=NUM_TRAJ, \n",
    "            device=None, dataset_name=DATASET_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
